{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04a658b0-f81d-45b5-a5a9-d51c714f7d29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install gradio openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af3762-6da7-4782-8985-62e8cd3f830d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import gradio as gr\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "openai.api_key = \"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\"  # Replace with your key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac5b45d1-b060-42fd-a645-548277938b83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Sagemaker notebooks may require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Running on public URL: https://566d99a7d6913f79c5.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://566d99a7d6913f79c5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(message, history):\n",
    "    history_openai_format = []\n",
    "    for human, assistant in history:\n",
    "        history_openai_format.append({\"role\": \"user\", \"content\": human })\n",
    "        history_openai_format.append({\"role\": \"assistant\", \"content\":assistant})\n",
    "    history_openai_format.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages= history_openai_format,\n",
    "        temperature=1.0,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    partial_message = \"\"\n",
    "    for chunk in response:\n",
    "        if len(chunk['choices'][0]['delta']) != 0:\n",
    "            partial_message = partial_message + chunk['choices'][0]['delta']['content']\n",
    "            yield partial_message\n",
    "\n",
    "gr.ChatInterface(predict).queue().launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd0bdf12-5331-45f5-8895-8566c25dc384",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image(prompt):\n",
    "    response = openai.Image.create(\n",
    "      prompt=prompt,\n",
    "      n=1,\n",
    "      size=\"512x512\"\n",
    "    )\n",
    "    url1 = response['data'][0]['url']\n",
    "    r = requests.get(url1)\n",
    "    img = Image.open(BytesIO(r.content))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83d7942e-971e-4266-8049-08f82e83a557",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://oaidalleapiprodscus.blob.core.windows.net/private/org-Szq050eGLZ905As8G7cRnNZM/user-XHlSxD36JH41gp8wjUUCoYUq/img-Ttyx84vpxjPfGu8ysIHz33S6.png?st=2023-08-27T20%3A40%3A52Z&se=2023-08-27T22%3A40%3A52Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-08-27T17%3A10%3A02Z&ske=2023-08-28T17%3A10%3A02Z&sks=b&skv=2021-08-06&sig=QQwqmFQo1TJtlAfeda2bv2FeUf5Z5wdeHkDSoVbYn9c%3D'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ef8376a-054b-41aa-9151-7fae78308036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = get_image('avatar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ef9af3e-5878-461f-95fd-a9452d642ded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img.save('data/avatar.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0ca7fb2-c292-454c-bd39-543a013ceee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class VirtualPet:\n",
    "    def __init__(self):\n",
    "        self.health = \"Healthy\"\n",
    "        self.mood = \"Happy\"\n",
    "        self.hunger = 0\n",
    "        self.thirst = 0\n",
    "        self.tiredness = 0\n",
    "        self.age = 0\n",
    "        self.character = \"egg with eyes\"\n",
    "        self.interactivity = \"Normal\"\n",
    "        self.environment = \"Day\"\n",
    "\n",
    "    def update(self, food=0, drink=0, sleep=0):\n",
    "        print(\"updating\")\n",
    "        self.age += 1\n",
    "        self.hunger = min(self.hunger +1 , 25)\n",
    "        self.thirst = min(self.thirst + 1, 25)\n",
    "        self.tiredness = min(self.tiredness + 1, 25)\n",
    "        \n",
    "        if food == 1:\n",
    "            self.hunger = self.hunger - 5\n",
    "        if drink == 1:\n",
    "            self.thirst = 0\n",
    "        if sleep == 1:\n",
    "            self.tiredness = 0\n",
    "        \n",
    "        if self.hunger >20 :\n",
    "            self.health = \"Tummy Ache\"\n",
    "        elif self.thirst > 20:\n",
    "            self.health = \"Headache\"\n",
    "        \n",
    "        else:\n",
    "            self.health = \"Healthy\"\n",
    "        \n",
    "        if self.tiredness > 20:\n",
    "            self.mood = \"Sleepy\"\n",
    "        else:\n",
    "            self.mood = \"Happy\" if self.tiredness < 15 and self.hunger < 15 and self.thirst < 15 else \"Grumpy\"\n",
    "        \n",
    "        self.interactivity = random.choice([\"Normal\", \"Playing games\", \"Going on adventures\", \"Telling jokes\"])\n",
    "        self.environment = random.choice([\"Day\", \"Night\", \"Sunny\", \"Rainy\"])\n",
    "        self.display_status()\n",
    "\n",
    "\n",
    "    def update_(update_json):\n",
    "        for name in [\"health\",\"mood\",\"age\",\"hunger\",\"tiredness\",\"thirst\",\"character\"]:\n",
    "            try:\n",
    "                attr = getattr(self, name)\n",
    "                attr = update_json[name]\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "    def gen_prompt(self):\n",
    "        return f\"A {self.character.lower()} virtual pet at age {self.age}. The pet is in a {self.environment.lower()} environment and is feeling {self.mood.lower()}. It has {self.health.lower()} health, with hunger level {self.hunger} and thirst level {self.thirst}. The pet looks {self.interactivity.lower()} as it interacts with the world.\"\n",
    "        \n",
    "    def display_status(self):\n",
    "        print(f\"Health: {self.health}\")\n",
    "        print(f\"Mood: {self.mood}\")\n",
    "        print(f\"Hunger: {self.hunger}\")\n",
    "        print(f\"Thirst: {self.thirst}\")\n",
    "        print(f\"Tiredness: {self.tiredness}\")\n",
    "        print(f\"Age: {self.age}\")\n",
    "        print(f\"Interactivity: {self.interactivity}\")\n",
    "        print(f\"Environment: {self.environment}\")\n",
    "\n",
    "# Create an instance of the VirtualPet class\n",
    "pet = VirtualPet()\n",
    "\n",
    "# Simulate passing time and updating status\n",
    "# for _ in range(30):\n",
    "#     food = random.choice([0, 0, 0, 1])  # Simulate feeding every 5 minutes\n",
    "#     drink = random.choice([0, 0, 0, 1])  # Simulate giving drink every 10 minutes\n",
    "#     sleep = random.choice([0, 0, 0, 1])  # Simulate sleeping every 20 minutes\n",
    "    \n",
    "#     pet.update(food, drink, sleep)\n",
    "#     pet.display_status()\n",
    "#     print(\"-\" * 30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5897bf03-9cbf-4939-a3d0-e9466a1f2b95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/gradio/utils.py:842: UserWarning: Expected 1 arguments for function <function <lambda> at 0x7f79861629e0>, received 0.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/utils.py:846: UserWarning: Expected at least 1 arguments for function <function <lambda> at 0x7f79861629e0>, received 0.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/utils.py:842: UserWarning: Expected 1 arguments for function <function <lambda> at 0x7f798a05acb0>, received 0.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/utils.py:846: UserWarning: Expected at least 1 arguments for function <function <lambda> at 0x7f798a05acb0>, received 0.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/utils.py:842: UserWarning: Expected 1 arguments for function <function <lambda> at 0x7f79876c2560>, received 0.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/utils.py:846: UserWarning: Expected at least 1 arguments for function <function <lambda> at 0x7f79876c2560>, received 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7868\n",
      "Sagemaker notebooks may require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Running on public URL: https://67577df2717825dc26.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://67577df2717825dc26.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with gr.Blocks() as demo:\n",
    "    image = gr.Image(type='pil')\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.ClearButton([msg, chatbot])\n",
    "    eat = gr.Button(value=\"Eat\")\n",
    "    eat.click(lambda x: pet.update(1,0,0))\n",
    "    drink = gr.Button(value=\"Drink\")\n",
    "    drink.click(lambda x: pet.update(0,1,0))\n",
    "    sleep = gr.Button(value=\"Sleep\")\n",
    "    sleep.click(lambda x: pet.update(0,0,1))\n",
    "\n",
    "    def respond(message, history):\n",
    "        pet_status_prompt = pet.gen_prompt()\n",
    "        system_prompt = f\" I want to role play game with you. You will be my smart virtual pet. I am a small kid. I will be in charge of feeding you. You need to let me know when you are tired, hungry or thirsty. \\n take into consideration that the Pet status is: {pet_status_prompt}\"\n",
    "        history_openai_format = [{'role':'system', \"content\":system_prompt}]\n",
    "        for human, assistant in history:\n",
    "            history_openai_format.append({\"role\": \"user\", \"content\": human })\n",
    "            history_openai_format.append({\"role\": \"assistant\", \"content\":assistant})\n",
    "        history_openai_format.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages= history_openai_format,\n",
    "            temperature=1.0,\n",
    "            # stream=True\n",
    "        )\n",
    "        # partial_message = \"\"\n",
    "        # for chunk in response:\n",
    "        #     if len(chunk['choices'][0]['delta']) != 0:\n",
    "        #         partial_message += partial_message + chunk['choices'][0]['delta']['content']\n",
    "        # return \"\",partial_message\n",
    "        # print(response['choices'][0])\n",
    "        content = response['choices'][0]['message']['content']\n",
    "        history.append((message,content))\n",
    "        img = get_image(\"Generate a cartoon-style image \"+pet_status_prompt)\n",
    "        pet.update(0,0,0)\n",
    "        return \"\",history,img\n",
    "\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot,image])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc1f14b-8bfc-41c4-812e-22824427353c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e6c58-1511-4a59-b6c2-7197216c8e03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
