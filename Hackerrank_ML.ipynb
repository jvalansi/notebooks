{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! curl https://s3.amazonaws.com/hr-testcases/597/assets/trainingdata.txt -o data/trainingdata.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "# create a df/itf per word\n",
    "# doc freq inverse token freq\n",
    "# create a tf idf vector per document\n",
    "# check which vector is closest\n",
    "from math import log\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV,RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.spatial import distance\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.utils import class_weight\n",
    "import random\n",
    "C = 9\n",
    "with open('data/trainingdata.txt') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "def normalize(text):\n",
    "    return text.lower()\n",
    "\n",
    "y = []\n",
    "data = []\n",
    "for line in lines[1:-1]:\n",
    "    c,line = line.split(' ',1)\n",
    "    y.append(int(c))\n",
    "    data.append(normalize(line))\n",
    "\n",
    "# print(len(cnt))\n",
    "# print(len([w for w in cnt if cnt[w]<=3]))\n",
    "# print(len(text.ENGLISH_STOP_WORDS))\n",
    "    \n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=8000, stop_words='english')\n",
    "vectorizer = vectorizer.fit(data)\n",
    "X = vectorizer.transform(data)\n",
    "y = np.array(y)\n",
    "# X,y = uniquify(X,y)\n",
    "\n",
    "# clf = LogisticRegression(solver='liblinear', multi_class='auto').fit(X, y)\n",
    "\n",
    "cnt = Counter(y)\n",
    "# print(cnt)\n",
    "\n",
    "def k_nearest(X_,k):\n",
    "    dist = cosine_similarity(X, X_).flatten()\n",
    "    first = np.argsort(dist)[-k:]\n",
    "    cs = [y[i] for i in first]\n",
    "    cnt_ = Counter(cs)\n",
    "    # cnt_ = Counter({c:n/cnt[c] for c,n in cnt_.items()})\n",
    "    # print(cnt_)\n",
    "    return cnt_.most_common(1)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_i = random.sample(range(N),N//10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_i = [i for i in range(N) if i not in test_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X[test_i, :]\n",
    "train = X[train_i, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = y[test_i]\n",
    "train_y = y[train_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.unique(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 labels,\n",
    "                                                 train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2578, 2: 1422, 4: 101, 6: 224, 5: 34, 7: 169, 8: 185, 3: 224})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2393813 ,  0.43398383,  2.75502232,  6.11014851, 18.15073529,\n",
       "        2.75502232,  3.65162722,  3.33581081])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights={i:w for i,w in  zip(labels,class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(class_weight=class_weights).fit(train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = RidgeClassifier(class_weight=class_weights).fit(train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05291970802919708"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(test)\n",
    "len((pred - test_y).nonzero()[0])/len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis = (pred - test_y).nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = test_i[mis[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: SparseEfficiencyWarning: Comparing sparse matrices using == is inefficient, try using != instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(vectorizer.transform([normalize(lines[i+1])]) == test[mis[j]]).toarray().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[mis[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[mis[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 transworld liquidating twt to distribute transworld corp liquidating trust said it expects to make an initial distribution to beneficiaries valued at dlrs per unit from the proceeds of the sale of hilton international co the value of the distribution assumes yesterday s closing price of ual s common stock of dlrs per share earlier ual announced that it completed the purchase of hilton international co for mln dlrs in cash and mln shares of ual inc common stock total value of the sale is about mln dlrs transworld said pursuant to the sale ual exercised its option to substitute cash for mln dlrs of debentures and shares of common stock transworld liquidating said each unit of beneficial interest in the trust will be allocated shares of ual common stock the aggregate value of the distribution is mln dlrs the balance of the cash in the trust will be held by the trust until april and will be used to satisfy all ouststanding liabilities and obligations of the trust after satisfaction of its liabilities and obligations the trust would make a second distribution to its beneficiaries of any remaining cash on or about april trading in the beneficial interests which are listed on the new york stock exchange will cease after today in order to receive the distribution beneficiaries must surrender the certificates representing their beneficial interests the trust was formed at year end to facilitate the sale of hilton international reuter '"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = np.zeros((C,C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "6 1\n",
      "2 1\n",
      "7 8\n",
      "7 8\n",
      "8 7\n",
      "6 2\n",
      "6 3\n",
      "2 7\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "2 6\n",
      "2 1\n",
      "3 7\n",
      "2 1\n",
      "8 7\n",
      "7 8\n"
     ]
    }
   ],
   "source": [
    "for j in mis:\n",
    "    print(pred[j],test_y[j])\n",
    "    conf[pred[j],test_y[j]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0., 17.,  0.,  0.,  0.,  0.,  1.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in range(20,40):\n",
    "#     clf = KNeighborsClassifier(n_neighbors=k).fit(train, train_y)\n",
    "#     pred = clf.predict(test)\n",
    "#     print(k,len((pred - test_y).nonzero()[0])/len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "k=30\n",
    "lines = \"\"\"This is a document \n",
    "this is another document \n",
    "documents are seperated by newlines\"\"\".split('\\n')\n",
    "for line in lines:\n",
    "    X_ = vectorizer.transform([normalize(line)])\n",
    "    clf.predict(X_)\n",
    "    print(k_nearest(X_,k))\n",
    "    print(clf.predict(X_)[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
