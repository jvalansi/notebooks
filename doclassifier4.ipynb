{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from collections import Counter\n",
    "# import fasttext.util\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "# fasttext.util.download_model('en', if_exists='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get generic word freqs\n",
    "# for each doc get word freqs\n",
    "# calculate top doc word freq / generic word freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install fasttext-wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1501908"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('data/SUBTLEXusfrequencyabove1.xls', index_col=0)\n",
    "freqs = df['FREQcount']\n",
    "freqs['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00320ad079d84707bdefbe92df36297c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=438.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "dirname = 'data/thoughts/Thoughts_en/'\n",
    "for fname in tqdm(os.listdir(dirname)):\n",
    "    if not fname.endswith('.docx'):\n",
    "        continue\n",
    "    with open(f\"{dirname}/{fname}\") as f:\n",
    "        data +=  [f.read()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [s for d in data for s in d.split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [s.strip() for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [re.sub('&#39;', '\\'', s) for s in sentences if s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for s in sentences for w in nltk.word_tokenize(s.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = [w for s in sentences for w in s.lower().split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85266"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = {c: n/(freqs[c] if c in freqs else 1) for c,n in cnt.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = {c: n/freqs[c] for c,n in cnt.items() if c in freqs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = sorted([(c,w) for w,c in tf_idf.items()], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12.5, 'asana'),\n",
       " (2.5714285714285716, 'shekels'),\n",
       " (2.5, 'inputs'),\n",
       " (2.5, 'app'),\n",
       " (1.5, 'startup'),\n",
       " (1.4285714285714286, 'neuron'),\n",
       " (1.0, 'stereoscopic'),\n",
       " (1.0, 'minimums'),\n",
       " (1.0, 'leftists'),\n",
       " (1.0, 'forums'),\n",
       " (1.0, 'explanatory'),\n",
       " (1.0, 'decreases'),\n",
       " (1.0, 'computation'),\n",
       " (0.8888888888888888, 'hazelnut'),\n",
       " (0.8333333333333334, 'transitive'),\n",
       " (0.8181818181818182, 'entropy'),\n",
       " (0.7777777777777778, 'fractal'),\n",
       " (0.7692307692307693, 'emails'),\n",
       " (0.75, 'melatonin'),\n",
       " (0.75, 'expend'),\n",
       " (0.7333333333333333, 'gt'),\n",
       " (0.7142857142857143, 'causality'),\n",
       " (0.7, 'bookmarks'),\n",
       " (0.6666666666666666, 'ui'),\n",
       " (0.6666666666666666, 'hippocampus'),\n",
       " (0.6666666666666666, 'derivatives'),\n",
       " (0.631578947368421, 'reminders'),\n",
       " (0.625, 'disadvantages'),\n",
       " (0.6, 'hierarchical'),\n",
       " (0.6, 'cocain'),\n",
       " (0.5, 'wardrobes'),\n",
       " (0.5, 'uploads'),\n",
       " (0.5, 'unpleasantly'),\n",
       " (0.5, 'thirsts'),\n",
       " (0.5, 'streamer'),\n",
       " (0.5, 'solvable'),\n",
       " (0.5, 'radars'),\n",
       " (0.5, 'pur'),\n",
       " (0.5, 'postpones'),\n",
       " (0.5, 'outgrowth'),\n",
       " (0.5, 'omnivorous'),\n",
       " (0.5, 'normalize'),\n",
       " (0.5, 'nihilism'),\n",
       " (0.5, 'maximizes'),\n",
       " (0.5, 'maximized'),\n",
       " (0.5, 'hazelnuts'),\n",
       " (0.5, 'formatting'),\n",
       " (0.5, 'creat'),\n",
       " (0.5, 'clustering'),\n",
       " (0.4444444444444444, 'leftist')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.26542819941986"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([f for f,w in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext.util.download_model('en', if_exists='ignore', dimension=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import io\n",
    "\n",
    "# def load_vectors(fname):\n",
    "#     fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "#     n, d = map(int, fin.readline().split())\n",
    "#     data = {}\n",
    "#     for line in fin:\n",
    "#         tokens = line.rstrip().split(' ')\n",
    "#         data[tokens[0]] = map(float, tokens[1:])\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip -P data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! unzip data/wiki-news-300d-1M.vec.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft = load_vectors('data/wiki-news-300d-1M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U sister\n",
    "# fails due to c++ compiler mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ! pip install -U sentence-transformers --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = np.ndarray.tolist(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a632a031dc664b02a061eeca7a26d7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=438.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "embeddings = []\n",
    "dirname = \"data/Thoughts_en\"\n",
    "for doc in tqdm(os.listdir(dirname)):\n",
    "    if not doc.endswith('.docx'):\n",
    "        continue\n",
    "    with open(os.path.join(dirname, doc)) as f:\n",
    "        data = f.read()\n",
    "    sentences = data.split('\\n')\n",
    "    sentence_embeddings = model.encode(sentences)\n",
    "    docs += sentences\n",
    "    embeddings += np.ndarray.tolist(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df.to_csv('data/Thoughts_en.vec.tsv', index=False, header=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [re.sub('\\t', '    ', doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Thoughts_en.txt.tsv', 'w') as f:\n",
    "    f.write('\\n'.join(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = '\\n'.join(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = sorted(cnt.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_cnt = [c for c in cnt if c[1]<=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in low_cnt:\n",
    "    all_docs = re.sub(c[0], '_', all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = all_docs.index(cnt[6][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_docs[i-10:i+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = all_docs.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = pd.DataFrame(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df['action'] = docs_df[0].apply(lambda x: 'need' in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df.columns = ['doc', 'is_action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df.to_csv('data/Thoughts_en.doc.tsv', index=False, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
